Data was created using :

Dataset for Gendered Language by Shweta Soundararajan. ~ 8k samples
Samples made with gpt5, gpt4, claude3.5, grok, deepseek, gemini ~ 3k samples

overall 11061
------------------------------------------------------------------------------------------------------------------
first model : roberta-base

on epoch 5 :

Validation Loss: 0.082

Accuracy: 98.1%

F1 Score: 98.1%

the model stopped improving on epoch 2, the validation loss started getting higher and training loss lower, so overfitting.

but at epoch 2 the training loss was still high, so in between we take epoch 3. 

on epoch 3:

Results (Epoch 3)

Validation loss: 0.0763 → very low, excellent generalization.

Validation accuracy: 98.10%

Validation F1 score: 98.10%

This is the one we'll take

------------------------------------------------------------------------------------------------------------------------------------------------

second model : microsoft/deberta-v3-base

Validation loss: 0.0497 → very low (better than your RoBERTa runs where it was ~0.076–0.12).

Validation accuracy: 98.1%

Validation F1 score: 98.1%

deberta did better than Roberta with the same parameters, so we'll go with deberta and we'll try to tweak the parameters to make it better.


After tweak:

Test loss: 0.0491 → very low (strong generalization).

Test accuracy: 98.55%

Test F1 score: 98.55%

This is the best thing we have. 


To stress-test the DeBERTa v3-base fine-tuned model, we created a set of 10 long, complex, discussion-style sentences (5 male-focused, 5 female-focused). These examples were deliberately nuanced, with subtle gender references and multi-clause structures designed to challenge the classifier.

Results:

The model correctly classified all 10/10 test cases.

Accuracy: 100%

F1 Score (macro): 1.0

Confidence: All predictions had high certainty (≥0.94 probability).

Conclusion:
The model demonstrates strong generalization ability, handling adversarial-style, context-heavy sentences just as well as short, straightforward ones. This suggests that the fine-tuned DeBERTa v3-base is robust and reliable for real-world forum-style discussions.
